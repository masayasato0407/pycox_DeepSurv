{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRC4scS8Z/Sz+nuoHoUilq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masayasato0407/pycox_DeepSurv/blob/main/pycox_DS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#pycoxを用いたDeepSurv予測\n",
        "\n",
        "モデル訓練用のtrain.csv、ハイパーパラメーター (今回はlearning rate[学習率])を設定するためのvalidation.csv、精度評価用のtest.csvを使用します。"
      ],
      "metadata": {
        "id": "L6hlvnLuo7cj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMTizwhmbxpX"
      },
      "outputs": [],
      "source": [
        "#pycoxのインストール\n",
        "!pip install pycox"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#必要なライブラリのインポート\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn_pandas import DataFrameMapper\n",
        "\n",
        "import torch\n",
        "import torchtuples as tt\n",
        "\n",
        "from pycox.datasets import metabric\n",
        "from pycox.models import CoxPH\n",
        "from pycox.evaluation import EvalSurv"
      ],
      "metadata": {
        "id": "B6xw9iBAb5Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ローカルファイルを直接アップロードする (train data)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "8W0CvHhSb5Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training dataの読み込み (df_trainという名前で読み込む)\n",
        "df_train=pd.read_csv (\"train.csv\",encoding=\"utf-8\")\n",
        "df_train.head"
      ],
      "metadata": {
        "id": "cd_WWeJlb5V7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ローカルファイルを直接アップロードする (validation data)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "nbJOlDPlb5YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#validation dataの読み込み (df_valという名前で読み込む)\n",
        "df_val=pd.read_csv (\"validation.csv\",encoding=\"utf-8\")\n",
        "df_val.head"
      ],
      "metadata": {
        "id": "xn3nt6fvdFOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ローカルファイルを直接アップロードする (test data)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "MdK4tyy0dFQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test dataの読み込み (df_testという名前で読み込む)\n",
        "df_test=pd.read_csv (\"test.csv\",encoding=\"utf-8\")\n",
        "df_test.head"
      ],
      "metadata": {
        "id": "eLDCNtzndFSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#今回は正規化をしないので、以下のコードを書く\n",
        "cols_leave = ['dis1', 'con1','con2', 'dis2', 'con3', 'con4','con5', 'con6', 'con7', 'con8','con9', 'dis3']\n",
        "leave = [(col, None) for col in cols_leave]\n",
        "x_mapper = DataFrameMapper(leave)"
      ],
      "metadata": {
        "id": "Y4VQ5tshdqHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ライブラリの制約上、float (実数を扱うことができるデータ型)32に変換する\n",
        "x_train = x_mapper.fit_transform(df_train).astype('float32')\n",
        "x_val = x_mapper.transform(df_val).astype('float32')\n",
        "x_test = x_mapper.transform(df_test).astype('float32')"
      ],
      "metadata": {
        "id": "r2Cc4AY-dFUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#target (timeとevent)を設定する\n",
        "get_target = lambda df: (df['time'].values, df['event'].values)\n",
        "y_train = get_target(df_train)\n",
        "y_val = get_target(df_val)\n",
        "durations_test, events_test = get_target(df_test)\n",
        "val = x_val, y_val"
      ],
      "metadata": {
        "id": "6FbXC3xZdFXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#モデルの作成\n",
        "in_features = x_train.shape[1]\n",
        "num_nodes = [32, 32]\n",
        "out_features = 1\n",
        "batch_norm = True\n",
        "dropout = 0.1\n",
        "output_bias = False\n",
        "\n",
        "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm,\n",
        "                              dropout, output_bias=output_bias)"
      ],
      "metadata": {
        "id": "0de_I283loNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#モデルのトレーニング \n",
        "#最適化のためのソフトウェア (オプティマイザーの指定が必要)→以下のtt.optim.Adam\n",
        "model = CoxPH(net, tt.optim.Adam)"
      ],
      "metadata": {
        "id": "jxvbmzi-l6r8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#最適なlearning rateを見つける\n",
        "batch_size = 256\n",
        "lrfinder = model.lr_finder(x_train, y_train, batch_size, tolerance=10)\n",
        "_ = lrfinder.plot()"
      ],
      "metadata": {
        "id": "vNqEDMn2dFaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#最適なlearning rateの提示\n",
        "lrfinder.get_best_lr()"
      ],
      "metadata": {
        "id": "5KIfSzRsdFcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#最適なlearning rateの設定\n",
        "#learning rateの最適化は少し高めになることもあり、こちらを採用せず手動で0.01にすることも多い\n",
        "model.optimizer.set_lr(0.042)"
      ],
      "metadata": {
        "id": "hW1ehJbtdFfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#epoch数などの設定\n",
        "#検証損失が改善しなくなった時点でトレーニングを停止するEarlyStoppingを設定 (2行目)\n",
        "#verbose→学習のログの表示の有無\n",
        "epochs = 512\n",
        "callbacks = [tt.callbacks.EarlyStopping()]\n",
        "verbose = True"
      ],
      "metadata": {
        "id": "HzP-SNGKmv2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#学習を行う\n",
        "%%time\n",
        "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
        "                val_data=val, val_batch_size=batch_size)"
      ],
      "metadata": {
        "id": "oMxiGtRLmv4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#評価のために、まずテストセットの生存推定値を得る必要があります。\n",
        "_ = model.compute_baseline_hazards()"
      ],
      "metadata": {
        "id": "Jgcbo0w2nig0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#生存推定値をデータフレームとして返す model.predict_surv_df で行う\n",
        "surv = model.predict_surv_df(x_test)"
      ],
      "metadata": {
        "id": "1w5onQS3mv7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "#We can use the EvalSurv class for evaluation the concordance, brier score and binomial log-likelihood. Setting censor_surv='km' means that we estimate the censoring distribution by Kaplan-Meier on the test set.\n",
        "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')"
      ],
      "metadata": {
        "id": "GR97EVV2oWXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#精度評価\n",
        "#EvalSurvクラスは，concordance，brier score，二項対数尤度の評価に用いることができます\n",
        "#censor_surv='km'とすると、テストセットに対してKaplan-Meierによる打ち切り分布の推定を行うことになります。\n",
        "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')"
      ],
      "metadata": {
        "id": "gXiM4qgroWvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testdataにおけるcindexの表示\n",
        "ev.concordance_td()"
      ],
      "metadata": {
        "id": "JlhtYgn0omka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testデータセットの説明変数を用いてtest setのサンプル0-4 (1行目のコードで指定)の予測の表示\n",
        "surv.iloc[:, :5].plot()\n",
        "plt.ylabel('S(t | x)')\n",
        "_ = plt.xlabel('Time')"
      ],
      "metadata": {
        "id": "vLsHa294mv9r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}